{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集路径，https://pan.baidu.com/s/1eSifHcA 提取码：g5qa下载解压img_path = glob.glob(r'C:\\Users\\z390\\Downloads\\faces\\*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集对象dataset, img_shape, _ = make_anime_dataset(img_path, batch_size, resize=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-d209f5561a23>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-d209f5561a23>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    classGenerator(keras.Model):#生成器网络def__init__(self):super(Generator,self).__init__()filter=64#转置卷积层1,输出channel为filter*8,核大小4,步长1,不使用padding,不使用偏置self.conv1=layers.Conv2DTranspose(filter*8,4,1,'valid',use_bias=False)self.bn1=layers.BatchNormalization()#转置卷积层2self.conv2=layers.Conv2DTranspose(filter*4,4,2,'same',use_bias=False)self.bn2=layers.BatchNormalization()#转置卷积层3self.conv3=layers.Conv2DTranspose(filter*2,4,2,'same',use_bias=False)self.bn3=layers.BatchNormalization()#转置卷积层4self.conv4=layers.Conv2DTranspose(filter*1,4,2,'same',use_bias=False)self.bn4=layers.BatchNormalization()#转置卷积层5self.conv5=layers.Conv2DTranspose(3,4,2,'same',use_bias=False\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "classGenerator(keras.Model):#生成器网络def__init__(self):super(Generator,self).__init__()filter=64#转置卷积层1,输出channel为filter*8,核大小4,步长1,不使用padding,不使用偏置self.conv1=layers.Conv2DTranspose(filter*8,4,1,'valid',use_bias=False)self.bn1=layers.BatchNormalization()#转置卷积层2self.conv2=layers.Conv2DTranspose(filter*4,4,2,'same',use_bias=False)self.bn2=layers.BatchNormalization()#转置卷积层3self.conv3=layers.Conv2DTranspose(filter*2,4,2,'same',use_bias=False)self.bn3=layers.BatchNormalization()#转置卷积层4self.conv4=layers.Conv2DTranspose(filter*1,4,2,'same',use_bias=False)self.bn4=layers.BatchNormalization()#转置卷积层5self.conv5=layers.Conv2DTranspose(3,4,2,'same',use_bias=False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "defcall(self,inputs,training=None):x=inputs#[z,100]#Reshape乘4D张量，方便后续转置卷积运算:(b,1,1,100)x=tf.reshape(x,(x.shape[0],1,1,x.shape[1]))x=tf.nn.relu(x)#激活函数#转置卷积-BN-激活函数:(b,4,4,512)x=tf.nn.relu(self.bn1(self.conv1(x),training=training))#转置卷积-BN-激活函数:(b,8,8,256)x=tf.nn.relu(self.bn2(self.conv2(x),training=training))#转置卷积-BN-激活函数:(b,16,16,128)x=tf.nn.relu(self.bn3(self.conv3(x),training=training))#转置卷积-BN-激活函数:(b,32,32,64)x=tf.nn.relu(self.bn4(self.conv4(x),training=training))#转置卷积-激活函数:(b,64,64,3)x=self.conv5(x)x=tf.tanh(x)#输出x范围-1~1,与预处理一致returnx"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classDiscriminator(keras.Model):#判别器def__init__(self):super(Discriminator,self).__init__()filter=64#卷积层1self.conv1=layers.Conv2D(filter,4,2,'valid',use_bias=False)self.bn1=layers.BatchNormalization()#卷积层2self.conv2=layers.Conv2D(filter*2,4,2,'valid',use_bias=False)self.bn2=layers.BatchNormalization()#卷积层3self.conv3=layers.Conv2D(filter*4,4,2,'valid',use_bias=False)self.bn3=layers.BatchNormalization()#卷积层4self.conv4=layers.Conv2D(filter*8,3,1,'valid',use_bias=False)self.bn4=layers.BatchNormalization()#卷积层5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self.conv5=layers.Conv2D(filter*16,3,1,'valid',use_bias=False)self.bn5=layers.BatchNormalization()#全局池化层self.pool=layers.GlobalAveragePooling2D()#特征打平层self.flatten=layers.Flatten()#2分类全连接层self.fc=layers.Dense(1)判别器的前向计算过程实现如下：defcall(self,inputs,training=None):#卷积-BN-激活函数:(4,31,31,64)x=tf.nn.leaky_relu(self.bn1(self.conv1(inputs),training=training))#卷积-BN-激活函数:(4,14,14,128)x=tf.nn.leaky_relu(self.bn2(self.conv2(x),training=training))#卷积-BN-激活函数:(4,6,6,256)x=tf.nn.leaky_relu(self.bn3(self.conv3(x),training=training))#卷积-BN-激活函数:(4,4,4,512)x=tf.nn.leaky_relu(self.bn4(self.conv4(x),training=training))#卷积-BN-激活函数:(4,2,2,1024)x=tf.nn.leaky_relu(self.bn5(self.conv5(x),training=training))#卷积-BN-激活函数:(4,1024)x=self.pool(x)#打平x=self.flatten(x)#输出，[b,1024]=>[b,1]logits=self.fc(x)returnlogits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defd_loss_fn(generator,discriminator,batch_z,batch_x,is_training):#计算判别器的误差函数#采样生成图片fake_image=generator(batch_z,is_training)#判定生成图片d_fake_logits=discriminator(fake_image,is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#判定真实图片d_real_logits=discriminator(batch_x,is_training)#真实图片与1之间的误差d_loss_real=celoss_ones(d_real_logits)#生成图片与0之间的误差d_loss_fake=celoss_zeros(d_fake_logits)#合并误差loss=d_loss_fake+d_loss_realreturnloss其中celoss_ones函数计算当前预测概率与标签1之间的交叉熵损失：defceloss_ones(logits):#计算属于与标签为1的交叉熵y=tf.ones_like(logits)loss=keras.losses.binary_crossentropy(y,logits,from_logits=True)returntf.reduce_mean(loss)celoss_zeros函数计算当前预测概率与标签0之间的交叉熵损失：defceloss_zeros(logits):#计算属于与便签为0的交叉熵y=tf.zeros_like(logits)loss=keras.losses.binary_crossentropy(y,logits,from_logits=True)returntf.reduce_mean(loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defg_loss_fn(generator,discriminator,batch_z,is_training):#采样生成图片fake_image=generator(batch_z,is_training)#在训练生成网络时，需要迫使生成图片判定为真d_fake_logits=discriminator(fake_image,is_training)#计算生成图片与1之间的误差loss=celoss_ones(d_fake_logits)returnlos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generator=Generator()#创建生成器generator.build(input_shape=(4,z_dim))discriminator=Discriminator()#创建判别器discriminator.build(input_shape=(4,64,64,3))#分别为生成器和判别器创建优化器g_optimizer=keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.5)d_optimizer=keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.5)训练部分实现如下：forepochinrange(epochs):#训练epochs次#1.训练判别器for_inrange(5):#采样隐藏向量batch_z=tf.random.normal([batch_size,z_dim])batch_x=next(db_iter)#采样真实图片#判别器前向计算withtf.GradientTape()astape:d_loss=d_loss_fn(generator,discriminator,batch_z,batch_x,is_training)grads=tape.gradient(d_loss,discriminator.trainable_variables)d_optimizer.apply_gradients(zip(grads,discriminator.trainable_variables))#2.训练生成器#采样隐藏向量batch_z=tf.random.normal([batch_size,z_dim])batch_x=next(db_iter)#采样真实图片#生成器前向计算withtf.GradientTape()astape:g_loss=g_loss_fn(generator,discriminator,batch_z,is_training)grads=tape.gradient(g_loss,generator.trainable_variables)g_optimizer.apply_gradients(zip(grads,generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
